{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# First Time Setups"
      ],
      "metadata": {
        "id": "T1L7Y5-MwbmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Stockfish"
      ],
      "metadata": {
        "id": "b3VX8tOnwkG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!   wget https://stockfishchess.org/files/stockfish_14_linux_x64_popcnt.zip && \\\n",
        "    unzip stockfish_14_linux_x64_popcnt.zip stockfish_14_linux_x64_popcnt/stockfish_14_x64_popcnt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY0mrDsNwlgk",
        "outputId": "342440f6-02be-437b-ccc7-083e4f4f593c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-11 00:55:42--  https://stockfishchess.org/files/stockfish_14_linux_x64_popcnt.zip\n",
            "Resolving stockfishchess.org (stockfishchess.org)... 104.25.159.9, 104.25.158.9, 172.67.80.249, ...\n",
            "Connecting to stockfishchess.org (stockfishchess.org)|104.25.159.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28531469 (27M) [application/zip]\n",
            "Saving to: ‘stockfish_14_linux_x64_popcnt.zip.2’\n",
            "\n",
            "stockfish_14_linux_ 100%[===================>]  27.21M  7.95MB/s    in 4.3s    \n",
            "\n",
            "2023-05-11 00:55:47 (6.29 MB/s) - ‘stockfish_14_linux_x64_popcnt.zip.2’ saved [28531469/28531469]\n",
            "\n",
            "Archive:  stockfish_14_linux_x64_popcnt.zip\n",
            "replace stockfish_14_linux_x64_popcnt/stockfish_14_x64_popcnt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "BEYD91Knlvry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chess\n",
        "!pip install python-lichess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t-132TIv4oK",
        "outputId": "cbdc6a11-6e39-47d5-ba77-37eb79b9843d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chess in /usr/local/lib/python3.10/dist-packages (1.9.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-lichess in /usr/local/lib/python3.10/dist-packages (0.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from python-lichess) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-lichess) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->python-lichess) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->python-lichess) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->python-lichess) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->python-lichess) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functionality"
      ],
      "metadata": {
        "id": "_pltGf4wwR4G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8C_gkQX04Q8"
      },
      "outputs": [],
      "source": [
        "import chess, chess.engine\n",
        "import os\n",
        "import random\n",
        "import numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to create a reachable random board"
      ],
      "metadata": {
        "id": "S_879AYCl1kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_board(max_depth=200):\n",
        "  board = chess.Board()\n",
        "  depth = random.randrange(0, max_depth)\n",
        "  for _ in range(depth):\n",
        "    all_moves = list(board.legal_moves)\n",
        "    random_move = random.choice(all_moves)\n",
        "    board.push(random_move)\n",
        "    if board.is_game_over():\n",
        "      break\n",
        "  return board"
      ],
      "metadata": {
        "id": "NxUMn44Tl7X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to get the Stockfish rating of a board"
      ],
      "metadata": {
        "id": "HTnUE8Iuw8ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sf = chess.engine.SimpleEngine.popen_uci(\"/content/stockfish_14_linux_x64_popcnt/stockfish_14_x64_popcnt\")\n",
        "def stockfish(board,depth=10):\n",
        "  result = sf.analyse(board, chess.engine.Limit(depth=depth))\n",
        "  output = result['score'].white().score()\n",
        "  if output is None: return 0\n",
        "  return output"
      ],
      "metadata": {
        "id": "vSN3QTJAw7m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test out the random_board and stockfish functions"
      ],
      "metadata": {
        "id": "Ubg09v_aPWtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "board = random_board()\n",
        "board"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "d8aGl0nhxco4",
        "outputId": "d42b7ff1-0977-4e0b-89a8-3402ceee8cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.2\" baseProfile=\"tiny\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r n b q k b n r\np p p p p p p p\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\nP P P P P P P P\nR N B Q K B N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>"
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stockfish(board))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE6g_SXky4Ga",
        "outputId": "ec6a9171-d49e-4830-8bf9-81898165da56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define functions to convert random_boards to data that Tensorflow can process  \n",
        "This creates a (14,8,8) numpy array that stores where the pieces are located and which ones are under attack, using only 1's and 0's"
      ],
      "metadata": {
        "id": "DRpgxklUTAQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squares_index = {\n",
        "  'a': 0,\n",
        "  'b': 1,\n",
        "  'c': 2,\n",
        "  'd': 3,\n",
        "  'e': 4,\n",
        "  'f': 5,\n",
        "  'g': 6,\n",
        "  'h': 7\n",
        "}\n",
        "\n",
        "\n",
        "# example: h3 -> 17\n",
        "def square_to_index(square):\n",
        "  letter = chess.square_name(square)\n",
        "  return 8 - int(letter[1]), squares_index[letter[0]]\n",
        "\n",
        "\n",
        "def split_dims(board):\n",
        "  # this is the 3d matrix\n",
        "  board3d = numpy.zeros((14, 8, 8), dtype=numpy.int8)\n",
        "\n",
        "  # here we add the pieces's view on the matrix\n",
        "  for piece in chess.PIECE_TYPES:\n",
        "    for square in board.pieces(piece, chess.WHITE):\n",
        "      idx = numpy.unravel_index(square, (8, 8))\n",
        "      board3d[piece - 1][7 - idx[0]][idx[1]] = 1\n",
        "    for square in board.pieces(piece, chess.BLACK):\n",
        "      idx = numpy.unravel_index(square, (8, 8))\n",
        "      board3d[piece + 5][7 - idx[0]][idx[1]] = 1\n",
        "\n",
        "  # add attacks and valid moves too\n",
        "  # so the network knows what is being attacked\n",
        "  aux = board.turn\n",
        "  board.turn = chess.WHITE\n",
        "  for move in board.legal_moves:\n",
        "      i, j = square_to_index(move.to_square)\n",
        "      board3d[12][i][j] = 1\n",
        "  board.turn = chess.BLACK\n",
        "  for move in board.legal_moves:\n",
        "      i, j = square_to_index(move.to_square)\n",
        "      board3d[13][i][j] = 1\n",
        "  board.turn = aux\n",
        "\n",
        "  return board3d"
      ],
      "metadata": {
        "id": "96T5zq2yTHdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test on the board generated"
      ],
      "metadata": {
        "id": "XzsvHla4TWvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_dims(board)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcF6qbaeTaFc",
        "outputId": "406158e3-be56-47f3-ad9b-798ff75d270d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 1, 0, 0, 0, 0, 1, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 1, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 0, 0, 0, 1]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 1, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 1, 0, 0, 0, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 1, 0, 0, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[1, 0, 0, 0, 0, 0, 0, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 1, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 1, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0]]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Data"
      ],
      "metadata": {
        "id": "Mf5yI4dkKe7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "GcnODpG4Qrl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete the datafile if it exists, just in case"
      ],
      "metadata": {
        "id": "1IsG-TeRMIwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(\"100.npz\"):\n",
        "  os.remove(\"100.npz\")\n",
        "  print(\"Deleted old dataset\")\n",
        "else:\n",
        "  print(\"Dataset not in path\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywvoOjSBL6CT",
        "outputId": "911d0902-7ce2-4e9e-9949-63df2344856c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset not in path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a bunch of numpy arrays and store them in the dataset file"
      ],
      "metadata": {
        "id": "9LjAidc2MMdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 100\n",
        "boards = [random_board() for i in range(num_samples)]\n",
        "b = np.array([split_dims(board) for board in boards])\n",
        "v = np.array([stockfish(board) for board in boards])\n",
        "\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vwo1RrmKgkK",
        "outputId": "5bc9b92f-8d24-4712-9c89-f56742786815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  800,  -784,  -838,   -99,  -215,  -225, -1261,  -281, -2946,\n",
              "         787, -1069, -2123,    97, -1728,     0,  8497,    54,  1062,\n",
              "        1838,  -769, -1492, -2690,  -565,   623,  1669,  -116,  -161,\n",
              "       -1378,  1713,  1269,  -169,    39,  1096,   712,  -415,  -511,\n",
              "        -276,  1012, -5717,  -647, -1284,  -640,   860,     0, -2369,\n",
              "        -755,  1081, -2238, -1756, -1462,    69,     0,  1126,  -118,\n",
              "        -976,     0,  3046,   -31,  1175,   760,   707,  -232,  -842,\n",
              "       -1301,     0,   604,  1307,   845,  -953,   508,   -63,   872,\n",
              "        1607,   961,  -593,    54,  1230,  1069,   907,  -337,  7313,\n",
              "         730,   307,  -510,  1853, -1454, -1015,  -761,  -119,   656,\n",
              "         723,  -384,   784,  1315,  -549,    75, -8174,  -357,  -905,\n",
              "       -1484,   536, -2646,  2038,   368,   446,  1484,  1484,   356,\n",
              "           0,   -13,   900,  -144,    65,     0,  1333,  -678,   829,\n",
              "        1192,     0, -1738,  2869,  -341,  1037,   129,  -327, -1530,\n",
              "        -992,   103,  1172,  -896,   -72,  -685, -1552, -1500,  -100,\n",
              "        -476,  1584,     0,  -402,  -630,  -961,  -695, -1376,  -103,\n",
              "        2615, -1261,   -80,     0, -1310,   319,  -180,  -392, -2048,\n",
              "        -172,  -372,  1069,     0,  1514,   853,   959,    85,  -753,\n",
              "       -1046,   904, -6295, -1168, -1275, -1317,   112,  -556,   715,\n",
              "         640,  1756,     0, -1507, -1050,     0,  -467, -1169,   275,\n",
              "         214,  -130, -1260,  1395,     0, -1416,  -745,  -932,   830,\n",
              "         -55, -2353,   507,   605,  1300,   -92, -2800, -2053,     0,\n",
              "       -1576,  1684, -1469,  1263,   875,   738,     0, -1462,  -540,\n",
              "        6863,  -524,  -173,  -602,   110,  -484,   361,   896, -1210,\n",
              "        -133,  -605,   619,   404,  -653,  -698,   375,  -504,    80,\n",
              "         235, -5809, -1946,  2246,   517,  -174,  1085,  2000,  -994,\n",
              "         -21, -1698,  1651,  -800, -1492,   505,   837,   932, -1095,\n",
              "       -1115,  1438,    42,  -951,     0,    71,  -437,  -453,   441,\n",
              "        -493,  -900,   153,  -153,  5302, -1407,   936,     0,     0,\n",
              "        1338,  1092,  -630,     0,  -723, -1248, -5425,  5788,     0,\n",
              "       -1038,   650,  -762,  1223,  -784,  -700,     0,     0,    -9,\n",
              "        -564,  -767,  -231,  -450,  1576,  -430,   -26,   861,   784,\n",
              "         814,  1315,  -799,   133,  -882,     0, -1347,     0,   892,\n",
              "       -1130,  -602,  -176,  -690,   -52,   633,   -24,  -693,   602,\n",
              "        2315, -1976,  -423,   620, -1130,  6296,  -205,     0,   715,\n",
              "         121,     0,  1238,  7163,   266,  1592, -1039,  -387,  -181,\n",
              "         790,  -291,  -450,   684,   791, -2794,     0,  -550,   581,\n",
              "         -70,  -233,   536,  2147,   -80, -2124,   386,    25,  -150,\n",
              "           0,   135,  -684,   457,   810, -1223,  -647,   791,   296,\n",
              "        -431,   553,   692,   175,  1769,  1225,  -807,   124, -1169,\n",
              "        -680,    87,  -582,     0,    50,   708,     0,  1107,  -250,\n",
              "         365,   321,   453,     0,     5, -1238,   531,     0,  1484,\n",
              "          25,  -375,    45,     0, -6277, -1282,  -672,    98,  -565,\n",
              "          86,  -165, -2469,   568,  1376,  -800,  1084,    16,   758,\n",
              "        -881,  2392,  -846, -1430,  1273,   784,   800, -2154,  -708,\n",
              "        -761,  2711,   119,     0,  1169,  -844, -1069,     0,     0,\n",
              "        -360,   112,     0,   262,  1218,   601,  1393,  -183,     0,\n",
              "        1784,    89,  -890,   510, -1807, -6083,     0,  -869,  -829,\n",
              "           0,     0,     0,  -881,   615,     0,  -592,     0,  2792,\n",
              "        -790,  -219,     0,  -425,  1538,   611,   311,  1743,     0,\n",
              "        1266,   678,   756,   604, -2138, -7727,  -536, -1715,   -37,\n",
              "       -1179,  -197,     0,     0, -1507, -1123,  -625,  1077,  -248,\n",
              "         162,  -708,   536,  -548,  5960,     0,  -721,   -36,     0,\n",
              "        1423,     0,     0,   854,  1020,   576,     0,   791, -1046,\n",
              "        -236,  -146,   743,   863,   -31, -1655,   182,  1119,  -522,\n",
              "          22,   597, -1646,    21, -2169,     0,     0,   805,  1261,\n",
              "        -763,  -492,   -59,  1476,   612,  1992,   430, -1343,     0,\n",
              "       -1061,    18, -1183,   822,   687,  -746,     0,   631,     0,\n",
              "       -1371,  1037,  1106,   461,  1711,   165,     0,   984,  -157,\n",
              "        -144,   350,  -491,     0,    -6,  -753,  -576,  -464,  -128,\n",
              "       -2504,   -89,   381,   -65,  -130,  1051,  -779, -1147,   199,\n",
              "           0,  1736,   889,   518,   753,  -453,  -149,     0,  1400,\n",
              "        1469,    50,    16, -2376,  -838,   928,  -817,   670,  -296,\n",
              "        -449, -1462, -2353,  -537,   -59,  -913,   192, -6938,     0,\n",
              "          13,     0,   -24,  2969, -1423,   515,   116,  -515,  -106,\n",
              "         570,   812, -5967,   -87,  1456, -1810,     0,     0,     0,\n",
              "         -10, -1187,  2279,   298,  1238,  -761,     0,  -586,     0,\n",
              "        1605, -1184,  -122,   922,  1629,   997,  -584,  -776,  -995,\n",
              "         152,  1644,  1130,  1218,   984,     0,  -493, -1114,  6105,\n",
              "        -463,     0,     0,   -50, -1400,  1476,  -947, -1053, -1409,\n",
              "        1142, -1386, -7504,     0,  1815,    71,  -981,  -113,     0,\n",
              "       -1035,  -163,  -746,   473,  1153,  1507,     0,     0,  -461,\n",
              "        -261,   660,  -341,   971,   576,   -71,  2505, -6306,   638,\n",
              "         119,   239, -1050,   395,   584,  1012,     0,  5510,     0,\n",
              "       -1023,  -121,     3,  1126,  -815, -1146,  2570,   902,   893,\n",
              "        1215,  -870, -1317, -1330,  -961,  1846, -2069,  -393,  -597,\n",
              "       -1307,  -376,  -692,  -403,   692,   114,    -3,   898,    97,\n",
              "        -534,  1053,   528,  1058,   -93,   708,  -348, -5690,     0,\n",
              "       -1154,   753,     0,  -669,  -999,   691,  2040,  -112, -1627,\n",
              "        -845,  2611,     0,  6004,  -122,   476, -6466,     0,   893,\n",
              "       -1038,  1584,  -700, -3297,  -492,  -381,   707,  1000, -1812,\n",
              "       -2442,   769,   845,  -253,   321,  1676, -1177,  -451,   961,\n",
              "           0,  1250,   138,    38,  1269,  -373,  1100,  1271, -1325,\n",
              "           0,   174, -1370,   837,  -217,   806,   685, -1300,   281,\n",
              "        -362, -1713, -1127,  -429, -1384,   799,   941, -2505,  1006,\n",
              "         820,   169,  -286, -1084,  -723, -7004,  -415,  1546, -1454,\n",
              "        -293,  1461,     0,     0,  -224,   682,     0,  -538,   923,\n",
              "       -2079,   -23,  -265,  -346,    34,  -838,     0,   -43,   180,\n",
              "       -1361,  -221,  1336,  -309,  1453,   338, -1797,    55, -1961,\n",
              "         561,  -738,    65,   163,     0,   715, -1869,    15,   -12,\n",
              "         715,  -484,   936, -1261, -1911,   -51,   715,  -823, -1246,\n",
              "         738,     0,   429,     0,   781,  1233,  -569,  1438,  -696,\n",
              "        -390,     0,   316,   456,   -30,   769, -1119,  -876,   616,\n",
              "         681,     0,  2261,  1207, -1376,   -54,  -992, -1979, -1103,\n",
              "         992,  -432,     0,  2353,   331,     0,   357,     0,    65,\n",
              "         163,  -380,    10,   440,  1746,   920,   109,  1100,  -111,\n",
              "           0,  -861,  1530, -6079,     0,   987,    -3, -6655, -1537,\n",
              "       -2492,   376,  1454,     0,  -653, -1523,  2436,  1117,  -149,\n",
              "         738,     0,   812,  -288,  -341,   -81, -1600,  -969,  -530,\n",
              "       -2825,  1026,     0,   221,  -484,  -593,   350,  -791,     0,\n",
              "           0,   459,     0, -2107,     0, -2930,   647,  -723, -1743,\n",
              "         241,  6079,  1325,     0,   345,   368,   160,     0,  -476,\n",
              "        5827,  -461, -1153,   763,   677,  1146,   947,     0,   907,\n",
              "        -776, -2300,  -861,  -659,    87,   208,   776,   692,  -846,\n",
              "         505,  -784,     0,   857,     0, -1200,  -954,   457, -1561,\n",
              "       -1061, -1637,  -584,   556,  1761, -1223,     0,  1134,   -30,\n",
              "       -1044,   256,  6890,  -168,  -961,   982,     5,  -606,   500,\n",
              "         953,  1207,  -919,   907, -1623,  -653,  2634,     2,  -752,\n",
              "         278,  1492,  6164,   463,   285,    50,    12,     0,     0,\n",
              "         987, -1073,  -761,  -713,   907,   944,     0,  5865,     0,\n",
              "         844,   219,   308,     0,   469,   500,   391,  -669,   -20,\n",
              "        1169])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy.savez(\"100\", b=b, v=v)"
      ],
      "metadata": {
        "id": "iyAMz0jGQON3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Model"
      ],
      "metadata": {
        "id": "eNxfQvsGTw4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Tensorflow libraries"
      ],
      "metadata": {
        "id": "d3k9aiofT2nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.utils as utils\n",
        "import tensorflow.keras.optimizers as optimizers"
      ],
      "metadata": {
        "id": "PIv37fw_T5sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the model, stack layers"
      ],
      "metadata": {
        "id": "LwwnI9arKycJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(conv_size, conv_depth):\n",
        "  board3d = layers.Input(shape=(14, 8, 8))\n",
        "\n",
        "  # adding the convolutional layers\n",
        "  x = board3d\n",
        "  for _ in range(conv_depth):\n",
        "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', activation='relu')(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, 'relu')(x)\n",
        "  x = layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "  return models.Model(inputs=board3d, outputs=x)"
      ],
      "metadata": {
        "id": "PO7LU4qpUCzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the model, stack layers"
      ],
      "metadata": {
        "id": "mm-RvktfK3vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_residual(conv_size, conv_depth):\n",
        "  board3d = layers.Input(shape=(14, 8, 8))\n",
        "\n",
        "  # adding the convolutional layers\n",
        "  x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same')(board3d)\n",
        "  for _ in range(conv_depth):\n",
        "    previous = x\n",
        "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Add()([x, previous])\n",
        "    x = layers.Activation('relu')(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "  return models.Model(inputs=board3d, outputs=x)"
      ],
      "metadata": {
        "id": "IVqK0sDHUGSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the model"
      ],
      "metadata": {
        "id": "NG6FR3NqUIpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(32, 4)"
      ],
      "metadata": {
        "id": "Oea4JfABUJ5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "Wmsa41ZsUQMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load `dataset.npz`, where the numpy arrays where stored.  \n",
        "Should output the sizes of the arrays, and the first numbers should match."
      ],
      "metadata": {
        "id": "xHVmhFgeK9Vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.callbacks as callbacks\n",
        "\n",
        "\n",
        "def get_dataset():\n",
        "\tcontainer = numpy.load('100.npz')\n",
        "\tb, v = container['b'], container['v']\n",
        "\tv = numpy.asarray(v / abs(v).max() / 2 + 0.5, dtype=numpy.float32) # normalization (0 - 1)\n",
        "\treturn b, v\n",
        "\n",
        "\n",
        "x_train, y_train = get_dataset()\n",
        "x_train.transpose()\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7XvdBfkUSMn",
        "outputId": "dd4039f4-5ec0-4f5f-8b82-370dd4279cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 14, 8, 8)\n",
            "(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the data into the model, and save the model into a file so that it can be loaded."
      ],
      "metadata": {
        "id": "425p2M0WLP5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
        "model.summary()\n",
        "checkpoint_filepath = '/tmp/checkpoint/'\n",
        "model_checkpointing_callback = ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    save_best_only= True,\n",
        ")\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=2048,\n",
        "          epochs=1000,\n",
        "          verbose=1,\n",
        "          validation_split=0.1,\n",
        "          callbacks=[callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
        "                     callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4),model_checkpointing_callback])\n",
        "\n",
        "model.save('100')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jGQkaxfUWwB",
        "outputId": "faa3abcd-9540-456f-fd45-546b02047b20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 14, 8, 8)]        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 8, 32)         2336      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 8, 32)         9248      \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 14, 8, 32)         9248      \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 8, 32)         9248      \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3584)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                229440    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 259,585\n",
            "Trainable params: 259,585\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0078"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 4s 4s/step - loss: 0.0078 - val_loss: 0.0098 - lr: 5.0000e-04\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0076"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 2s 2s/step - loss: 0.0076 - val_loss: 0.0089 - lr: 5.0000e-04\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0075"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 3s 3s/step - loss: 0.0075 - val_loss: 0.0088 - lr: 5.0000e-04\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0073 - val_loss: 0.0090 - lr: 5.0000e-04\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0070 - val_loss: 0.0092 - lr: 5.0000e-04\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 4s 4s/step - loss: 0.0069 - val_loss: 0.0087 - lr: 5.0000e-04\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 4s 4s/step - loss: 0.0066 - val_loss: 0.0082 - lr: 5.0000e-04\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0064"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 3s 3s/step - loss: 0.0064 - val_loss: 0.0079 - lr: 5.0000e-04\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0062 - val_loss: 0.0081 - lr: 5.0000e-04\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0059"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 2s 2s/step - loss: 0.0059 - val_loss: 0.0079 - lr: 5.0000e-04\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0057"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 2s 2s/step - loss: 0.0057 - val_loss: 0.0075 - lr: 5.0000e-04\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.0057 - val_loss: 0.0077 - lr: 5.0000e-04\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 0.0054 - val_loss: 0.0076 - lr: 5.0000e-04\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0053"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 2s 2s/step - loss: 0.0053 - val_loss: 0.0073 - lr: 5.0000e-04\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0053 - val_loss: 0.0076 - lr: 5.0000e-04\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0050 - val_loss: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0048"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 3s 3s/step - loss: 0.0048 - val_loss: 0.0072 - lr: 5.0000e-04\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0048 - val_loss: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0045 - val_loss: 0.0075 - lr: 5.0000e-04\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.0044"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 2s 2s/step - loss: 0.0044 - val_loss: 0.0071 - lr: 5.0000e-04\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0044 - val_loss: 0.0072 - lr: 5.0000e-04\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 0.0042 - val_loss: 0.0075 - lr: 5.0000e-04\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 0.0042 - val_loss: 0.0071 - lr: 5.0000e-04\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0041 - val_loss: 0.0073 - lr: 5.0000e-04\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.0038 - val_loss: 0.0076 - lr: 5.0000e-04\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0038 - val_loss: 0.0072 - lr: 5.0000e-04\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 0.0038 - val_loss: 0.0075 - lr: 5.0000e-04\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.0036 - val_loss: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 0.0035 - val_loss: 0.0072 - lr: 5.0000e-04\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0035 - val_loss: 0.0077 - lr: 5.0000e-04\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0034 - val_loss: 0.0073 - lr: 5.0000e-04\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0032 - val_loss: 0.0073 - lr: 5.0000e-04\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.0032 - val_loss: 0.0077 - lr: 5.0000e-04\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 0.0032 - val_loss: 0.0073 - lr: 5.0000e-04\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.0030 - val_loss: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0029 - val_loss: 0.0077 - lr: 5.0000e-04\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0028 - val_loss: 0.0073 - lr: 5.0000e-04\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.0028 - val_loss: 0.0077 - lr: 5.0000e-04\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.0027 - val_loss: 0.0075 - lr: 5.0000e-04\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 0.0026 - val_loss: 0.0075 - lr: 5.0000e-04\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.0025 - val_loss: 0.0078 - lr: 5.0000e-04\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0025 - val_loss: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0024 - val_loss: 0.0079 - lr: 5.0000e-04\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.0024 - val_loss: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0022 - val_loss: 0.0076 - lr: 5.0000e-04\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0021 - val_loss: 0.0076 - lr: 5.0000e-04\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - val_loss: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - val_loss: 0.0079 - lr: 5.0000e-04\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 0.0020 - val_loss: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0021 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.0021 - val_loss: 0.0074 - lr: 5.0000e-04\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 0.0019 - val_loss: 0.0077 - lr: 5.0000e-04\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 0.0017 - val_loss: 0.0079 - lr: 5.0000e-04\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.0017 - val_loss: 0.0075 - lr: 5.0000e-04\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.0017 - val_loss: 0.0080 - lr: 5.0000e-04\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 0.0016 - val_loss: 0.0078 - lr: 5.0000e-04\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 0.0014 - val_loss: 0.0077 - lr: 5.0000e-04\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 0.0015 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.0015 - val_loss: 0.0077 - lr: 5.0000e-04\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.0014 - val_loss: 0.0080 - lr: 5.0000e-04\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0013 - val_loss: 0.0079 - lr: 5.0000e-04\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0012 - val_loss: 0.0077 - lr: 5.0000e-04\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0013 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0012 - val_loss: 0.0078 - lr: 5.0000e-04\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 1s 818ms/step - loss: 0.0011 - val_loss: 0.0080 - lr: 5.0000e-04\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 0.0010 - val_loss: 0.0081 - lr: 5.0000e-04\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 0.0010 - val_loss: 0.0079 - lr: 5.0000e-04\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 0.0010 - val_loss: 0.0084 - lr: 5.0000e-04\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0011 - val_loss: 0.0079 - lr: 5.0000e-04\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 0.0010 - val_loss: 0.0084 - lr: 5.0000e-04\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 9.3723e-04 - val_loss: 0.0080 - lr: 5.0000e-04\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 8.2744e-04 - val_loss: 0.0080 - lr: 5.0000e-04\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 7.7201e-04 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 7.8090e-04 - val_loss: 0.0080 - lr: 5.0000e-04\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 8.0492e-04 - val_loss: 0.0086 - lr: 5.0000e-04\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.0235e-04 - val_loss: 0.0081 - lr: 5.0000e-04\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.8228e-04 - val_loss: 0.0086 - lr: 5.0000e-04\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.3159e-04 - val_loss: 0.0081 - lr: 5.0000e-04\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 6.6705e-04 - val_loss: 0.0084 - lr: 5.0000e-04\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 5.9531e-04 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 5.4507e-04 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 5.2569e-04 - val_loss: 0.0085 - lr: 5.0000e-04\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 5.3101e-04 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 5.6632e-04 - val_loss: 0.0089 - lr: 5.0000e-04\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 6.5711e-04 - val_loss: 0.0084 - lr: 5.0000e-04\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 8.6475e-04 - val_loss: 0.0095 - lr: 5.0000e-04\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 0.0010 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 8.2453e-04 - val_loss: 0.0084 - lr: 5.0000e-04\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 4.2670e-04 - val_loss: 0.0090 - lr: 5.0000e-04\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 6.8183e-04 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 6.2674e-04 - val_loss: 0.0083 - lr: 5.0000e-04\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.1481e-04 - val_loss: 0.0091 - lr: 5.0000e-04\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.4094e-04 - val_loss: 0.0084 - lr: 5.0000e-04\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.3322e-04 - val_loss: 0.0085 - lr: 5.0000e-04\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 4.0330e-04 - val_loss: 0.0092 - lr: 5.0000e-04\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 5.5209e-04 - val_loss: 0.0085 - lr: 5.0000e-04\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 3.5907e-04 - val_loss: 0.0086 - lr: 5.0000e-04\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 3.2793e-04 - val_loss: 0.0092 - lr: 5.0000e-04\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 4.7226e-04 - val_loss: 0.0085 - lr: 5.0000e-04\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 3.7525e-04 - val_loss: 0.0085 - lr: 5.0000e-05\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 3.5461e-04 - val_loss: 0.0086 - lr: 5.0000e-05\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 2.9586e-04 - val_loss: 0.0086 - lr: 5.0000e-05\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 1s 807ms/step - loss: 2.6168e-04 - val_loss: 0.0088 - lr: 5.0000e-05\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 2.7791e-04 - val_loss: 0.0089 - lr: 5.0000e-05\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 3.1205e-04 - val_loss: 0.0089 - lr: 5.0000e-05\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 3.1816e-04 - val_loss: 0.0088 - lr: 5.0000e-05\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.8952e-04 - val_loss: 0.0087 - lr: 5.0000e-05\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.5883e-04 - val_loss: 0.0087 - lr: 5.0000e-05\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.5532e-04 - val_loss: 0.0086 - lr: 5.0000e-05\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 2.7362e-04 - val_loss: 0.0086 - lr: 5.0000e-05\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 2.8591e-04 - val_loss: 0.0086 - lr: 5.0000e-05\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 2.7638e-04 - val_loss: 0.0087 - lr: 5.0000e-05\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 2.5615e-04 - val_loss: 0.0087 - lr: 5.0000e-06\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 2.5434e-04 - val_loss: 0.0087 - lr: 5.0000e-06\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 2.5245e-04 - val_loss: 0.0087 - lr: 5.0000e-06\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 2.5067e-04 - val_loss: 0.0087 - lr: 5.0000e-06\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 2.4914e-04 - val_loss: 0.0087 - lr: 5.0000e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stockfish vs Model position rating"
      ],
      "metadata": {
        "id": "gPAGFcJgVnjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate a random board, and have both the model and stockfish rate it"
      ],
      "metadata": {
        "id": "-ikLLzWVVuIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "board = random_board()\n",
        "\n",
        "from tensorflow.keras import models\n",
        "model = models.load_model('1000')\n",
        "\n",
        "def minimax_eval(board):\n",
        "  board3d = split_dims(board)\n",
        "  board3d = numpy.expand_dims(board3d, 0)\n",
        "  return model(board3d)[0][0]\n",
        "\n",
        "print(f'\\n{board}')\n",
        "print(\"Stockfish (not normalized):\", stockfish(board))\n",
        "print(\"TensorFlow:\", minimax_eval(board))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzzTMOUJVy-m",
        "outputId": "3bf1a0c1-7f5b-4891-a7d2-d3a67fa70602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ". . . . . . b .\n",
            ". . . . . . k .\n",
            ". . . . . N . p\n",
            ". . . . B . . P\n",
            "P P . . . . . .\n",
            ". . r . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . K\n",
            "Stockfish (not normalized): 890\n",
            "TensorFlow: tf.Tensor(0.51143026, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gametree Implementation"
      ],
      "metadata": {
        "id": "JgYnKGyLUefE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import model from file!"
      ],
      "metadata": {
        "id": "8eVXvKBvLalP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "model = models.load_model('1000')"
      ],
      "metadata": {
        "id": "FQ1pv4f1UlJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimax, with alpha beta pruning."
      ],
      "metadata": {
        "id": "6VKa09lxLdW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# used for the minimax algorithm\n",
        "def minimax_eval(board):\n",
        "  board3d = split_dims(board)\n",
        "  board3d = numpy.expand_dims(board3d, 0)\n",
        "  return model(board3d)[0][0]\n",
        "\n",
        "\n",
        "def minimax(board, depth, alpha, beta, maximizing_player):\n",
        "  if depth == 0 or board.is_game_over():\n",
        "    return minimax_eval(board)\n",
        "  \n",
        "  if maximizing_player:\n",
        "    max_eval = -numpy.inf\n",
        "    for move in board.legal_moves:\n",
        "      board.push(move)\n",
        "      eval = minimax(board, depth - 1, alpha, beta, False)\n",
        "      board.pop()\n",
        "      max_eval = max(max_eval, eval)\n",
        "      alpha = max(alpha, eval)\n",
        "      if beta <= alpha:\n",
        "        break\n",
        "    return max_eval\n",
        "  else:\n",
        "    min_eval = numpy.inf\n",
        "    for move in board.legal_moves:\n",
        "      board.push(move)\n",
        "      eval = minimax(board, depth - 1, alpha, beta, True)\n",
        "      board.pop()\n",
        "      min_eval = min(min_eval, eval)\n",
        "      beta = min(beta, eval)\n",
        "      if beta <= alpha:\n",
        "        break\n",
        "    return min_eval\n",
        "\n",
        "\n",
        "# this is the actual function that gets the move from the neural network\n",
        "def get_ai_move(board, depth):\n",
        "  max_move = None\n",
        "  max_eval = -numpy.inf\n",
        "\n",
        "  for move in board.legal_moves:\n",
        "    board.push(move)\n",
        "    eval = minimax(board, depth - 1, -numpy.inf, numpy.inf, False)\n",
        "    board.pop()\n",
        "    if eval > max_eval:\n",
        "      max_eval = eval\n",
        "      max_move = move\n",
        "  \n",
        "  return max_move"
      ],
      "metadata": {
        "id": "cYksTP-ZUp-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the AI vs installed Stockfish engine, automatically moving pieces."
      ],
      "metadata": {
        "id": "udjrOKy7Lkk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing code AI(white) vs Stockfish(black)\n",
        "board = chess.Board()\n",
        "from IPython.display import clear_output\n",
        "with chess.engine.SimpleEngine.popen_uci(\"/content/stockfish_14_linux_x64_popcnt/stockfish_14_x64_popcnt\") as engine:\n",
        "    while True:\n",
        "        clear_output(wait=True)\n",
        "        move = get_ai_move(board, 1)\n",
        "        board.push(move)\n",
        "        print(f'\\n{board}')\n",
        "        if board.is_game_over():\n",
        "            print('gg')\n",
        "            break\n",
        "        move = engine.analyse(board, chess.engine.Limit(time=0.1), info=chess.engine.INFO_PV)['pv'][0]\n",
        "        board.push(move)\n",
        "        print(f'\\n{board}')\n",
        "        if board.is_game_over():\n",
        "            print('gg')\n",
        "            break"
      ],
      "metadata": {
        "id": "Z7hRCDalUsfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2257b74-3755-4a8e-e6b1-37f4d7454616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "r n b . k . . r\n",
            "p . . p . p p p\n",
            ". . p . p . . .\n",
            ". . b . P . . .\n",
            ". . . . . . . .\n",
            ". . . . . q . .\n",
            ". . P P . P . P\n",
            ". . . . . K . .\n",
            "\n",
            "r n b . k . . r\n",
            "p . . p . p p p\n",
            ". . p . p . . .\n",
            ". . b . P . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . P P . q . P\n",
            ". . . . . K . .\n",
            "gg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Stockfish annihilating the AI, because it is a pale imitation of the original"
      ],
      "metadata": {
        "id": "mc2vsrR4d1sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "board"
      ],
      "metadata": {
        "id": "edHj3wQbdxGw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "f56fb75c-bd06-4bda-f3bc-c6487ad774a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Board('rnb1k2r/p2p1ppp/2p1p3/2b1P3/8/8/2PP1q1P/5K2 w kq - 0 16')"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.2\" baseProfile=\"tiny\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r n b . k . . r\np . . p . p p p\n. . p . p . . .\n. . b . P . . .\n. . . . . . . .\n. . . . . . . .\n. . P P . q . P\n. . . . . K . .</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g><radialGradient id=\"check_gradient\" r=\"0.5\"><stop offset=\"0%\" stop-color=\"#ff0000\" stop-opacity=\"1.0\" /><stop offset=\"50%\" stop-color=\"#e70000\" stop-opacity=\"1.0\" /><stop offset=\"100%\" stop-color=\"#9e0000\" stop-opacity=\"0.0\" /></radialGradient></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark lastmove f2\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light lastmove f3\" stroke=\"none\" fill=\"#cdd16a\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"check\" fill=\"url(#check_gradient)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(240, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 150)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 150)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>"
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move by move testing code AI(white) vs user(black)\n",
        "board = chess.Board()\n",
        "from IPython.display import clear_output\n",
        "\n",
        "with chess.engine.SimpleEngine.popen_uci(\"/content/stockfish_14_linux_x64_popcnt/stockfish_14_x64_popcnt\") as engine:\n",
        "    while True:\n",
        "        clear_output(wait=True)\n",
        "        move = get_ai_move(board, 1)\n",
        "        board.push(move)\n",
        "        print(move)\n",
        "        print(f'\\n{board}')\n",
        "        if board.is_game_over():\n",
        "            print('gg')\n",
        "            break\n",
        "        input_var = input()\n",
        "        move = chess.Move.from_uci(input_var)\n",
        "        board.push(move)\n",
        "        print(move)\n",
        "        print(f'\\n{board}')\n",
        "        if board.is_game_over():\n",
        "            print('gg')\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "OQj_bJkDU6gX",
        "outputId": "3823f528-66d6-4cb2-ca23-55f49f0ffb88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g1f3\n",
            "\n",
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . N . .\n",
            "P P P P P P P P\n",
            "R N B Q K B . R\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-be1818598479>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0minput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_uci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}